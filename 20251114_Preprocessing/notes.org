#+TITLE: fMRI Data Pre-processing

* Copy over data
:PROPERTIES:
:header-args:bash:  :tangle scripts/01_copy_data.sh
:header-args:bash+: :shebang "#!/usr/bin/env bash"
:header-args:bash+: :mkdirp yes
:END:

Copy over the data from network storage to CHPC.
#+begin_src bash
# * Copy data from the NAS to CHPC for processing

# * Environment
# ** Remote NAS (source)
r1id="vkoppelmans"
r1ip="eindhoven.synology.me"
r1dir="/volume1/Backup/Thalia/Kladblok/20190830_Koppelmans\
/20240816_NMD_fMRIprep_Tethys/data/20240715_BIDS"

# ** CHPC (target)
r2id="u6012627"
r2ip="notchpeak.chpc.utah.edu"
r2dir="/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok\
/20251114_NMD_fMRI"


# * Copy data from NAS to local
# NAS does not allow scp protocol, and rsync does not allow remote-to-remote
# copying, so I will need to copy the data over from NAS to local, and then from
# local to CHPC.

# ** Copy NAS to local
tdir=$(mktemp -d)
rsync -avmhe ssh ${r1id}@${r1ip}:${r1dir} "${tdir}"

# ** Copy local to CHPC
# * Create output folder
ssh "${r2id}@${r2ip}" mkdir -p "${r2dir}"

# ** Copy over the data
rsync -avmhe ssh "${tdir}/20240715_BIDS" ${r2id}@${r2ip}:${r2dir}
#+end_src

The total data size is 36.22G.

* Build fMRIprep on CHPC
:PROPERTIES:
:header-args:bash: :tangle no
:END:

#+NAME: build_fmriprep_chpc
#+begin_src bash
#SBATCH --account=koppelmans-np
#SBATCH --mail-user=u6012627@utah.edu
#SBATCH --partition=koppelmans-shared-np
#SBATCH --job-name=build_fmriprep
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --mem=24G
#SBATCH --time=3:00:00
#SBATCH -o build_fmriprep_sif-%j.out-%N
#SBATCH -e build_fmriprep_sif-%j.err-%N

# * Environment
odir="/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Software\
/SingularityImages"

# * Load singularity/apptainer
module load apptainer

# * Version
container_version="25.2.3"

# * Environment
apptainer \
    build \
    "${odir}/fmriprep-${container_version}.simg" \
    "docker://nipreps/fmriprep:${container_version}"

exit
#+end_src

** TANGLE (local) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle scripts/02_build_fmrirep.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<build_fmriprep_chpc>>
#+end_src

** TANGLE (CHPC) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle  /ssh:u6012627@notchpeak.chpc.utah.edu:/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Software/SingularityImages/build_fMRIprep_25.2.3.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<build_fmriprep_chpc>>
#+end_src

* Flip Brain of NMD004
:PROPERTIES:
:header-args:bash: :tangle no
:END:

We are analyzing dominant hand grip strength. Subject NMD004 is left handed, all others are right handed. I will flip the MRI data of the left-handed subject for group level analyses later.

#+NAME: lr_flip_brain_nmd004
#+begin_src bash
#SBATCH --account=koppelmans-np
#SBATCH --mail-user=u6012627@utah.edu
#SBATCH --partition=koppelmans-shared-np
#SBATCH --job-name=lr_flip_NMD004
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --mem=12G
#SBATCH --time=1:00:00
#SBATCH -o lr_flip_NMD004-%j.out-%N
#SBATCH -e lr_flip_NMD004-%j.err-%N

# This script makes a backup of the data of subject NMD004, the only left
# handed subject in the data set. It then flips the MRI data left-to-right to
# ensure that we will be able to do group level analyses for the dominant hand.

# * Environment
dir="/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok\
/20251114_NMD_fMRI/20240715_BIDS"
cd "${dir}" || exit


# * Load FSL module
module load fsl


# * Backup the original data
# Only do this if the backup file does not exists. This will prevent overwriting
# the true original data.
bkpfile="${dir}/sub-NMD004_non_flipped_bkp.gz"
if [ ! -f "${bkpfile}" ]; then
    echo "Backing up data for sub-NMD004"
    tar -zcf "${bkpfile}" "sub-NMD004"
    echo $(basename "${bkpfile}") >> .bidsignore
    echo "scripts/" >> .bidsignore
else
    echo "Data for sub-NMD004 already backed up. Skipping..."
fi


# * List NMD004's nifti files
ddir="${dir}/sub-NMD004"
files=($(find "${ddir}" -iname "*.nii.gz" | sort))


# * Flip each nifti file
for file in ${files[@]}; do

    fbase=$(echo "${file}" | sed "s#${ddir}#..#g")
    echo "$(tput setaf 3)Left-Right flipping:$(tput sgr0) ${fbase}"
    fslswapdim "${file}" -x y z "${file}"

done


exit
#+end_src

** TANGLE (local) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle scripts/03_lr_flip_brain_nmd004.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<lr_flip_brain_nmd004>>
#+end_src

** TANGLE (CHPC) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle  /ssh:u6012627@notchpeak.chpc.utah.edu:/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok/20251114_NMD_fMRI/20240715_BIDS/scripts/lr_flip_brain_nmd004.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<lr_flip_brain_nmd004>>
#+end_src

* Python function to populate the intended for fields.
:PROPERTIES:
:header-args:python: :tangle no
:END:

This is necessary to ensure that fMRIprep will recognize the AP/PA maps to unwarp the fMRI data.

#+NAME: populate_intended_for
#+begin_src python
# * Libraries
import argparse
from glob import glob
import json
from shutil import copy2


# * Import arguments
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='Populate fieldmap json files intended for fields'
    )
    parser.add_argument('--sid', required=True, help='Subject ID.')
    parser.add_argument('--ses', required=True, help='Session ID.')
    parser.add_argument('--path', required=True, help='Root folder containing subject folders')
    # ** Parse arguments
    args = parser.parse_args()


# * Create class for patching
class fixjson:
    def __init__(self, sid, ses, path):

        # ** Store input arguments
        self.subid = str(sid)
        self.sesid = str(ses)
        self.base = path

        # ** Build paths
        self.idir = self.base + "/sub-" + self.subid + "/ses-" + self.sesid
        self.idir_func = self.idir + "/func"
        self.idir_fmap = self.idir + "/fmap"

    # ** Locate funtional data
    def locate_nii(self, sequence):
        # *** Find the nifti data paths
        self.niis = sorted(glob(self.idir_func + f"/*{sequence}*nii.gz"))
        # *** Remove root + subject path from these paths
        self.niis = [
            x.replace(self.base + "/sub-" + self.subid + "/", "")
            for x in self.niis
        ]
        return self.niis

    # ** Locate field map json files
    # This should bring up exactly two files: AP and PA for a particular sequence
    def locate_json(self, sequence):
        # *** Find the json data paths
        self.json = sorted(glob(self.idir_fmap + f"/*{sequence}*json"))
        return self.json

    # ** Loop over json files and inject 'intended for' relative path
    def doinject(self, sequence):

        # *** Loop over the json AP/PA images
        for my_json in self.locate_json(sequence):

            # **** Create backup
            # file_bkp = my_json.replace("json", "json_bkp")
            # copy2(my_json, file_bkp)

            # **** Load json file
            with open(my_json) as json_file:
                self.tmp_json = json.load(json_file)

                # ***** Announce
                print(f"Populating IntendedFor field of {my_json.split('/')[-1]} with {self.locate_nii(sequence)[0]}")

                # ***** Inject fMRI path into 'intended for' field
                self.tmp_json['IntendedFor'] = self.locate_nii(sequence)

            # **** Save the edited json over the original file
            with open(my_json, "w") as write_file:
                json.dump(self.tmp_json, write_file, indent=4)


# * Apply patch
# ** Test
# my_fix_object = fixjson("NMD001", "01", "/datadisk/tmp/NMD")
# for sequence in ['handdom', 'rest']:
#     my_fix_object.doinject(sequence)

# ** Production
my_fix_object = fixjson(args.sid, args.ses, args.path)
for sequence in ['handdom', 'rest']:
    my_fix_object.doinject(sequence)
#+end_src

Test
#+begin_src bash :tangle no
# * Load the virtual environment
source "${HOME}/Software/syspyvenv/bin/activate"

# * Environment
script="/datadisk/Utah/Kladblok/20201120_Margolis_NMD/20220504_Data_Processing\
/20251113_BayesfMRI/20251114_Preprocessing/scripts/04_fix_json.py"
dir="/datadisk/tmp/NMD"

# * Environment
python3 \
    "${script}" \
    --sid "NMD001" \
    --ses "01" \
    --path "${dir}"
#+end_src

** TANGLE (local) :noexport:
:PROPERTIES:
:header-args:python:  :shebang "#!/usr/bin/env python"
:header-args:python+: :tangle scripts/04_fix_json.py
:header-args:python+: :mkdirp yes
:header-args:python+: :noweb yes
:END:

#+begin_src python
<<populate_intended_for>>
#+end_src

** TANGLE (CHPC) :noexport:
:PROPERTIES:
:header-args:python:  :shebang "#!/usr/bin/env python"
:header-args:python+: :tangle  /ssh:u6012627@notchpeak.chpc.utah.edu:/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok/20251114_NMD_fMRI/20251114_BIDS_prepped/scripts/fix_json.py
:header-args:python+: :mkdirp yes
:header-args:python+: :noweb yes
:END:

#+begin_src python
<<populate_intended_for>>
#+end_src

* Prepare dataset for fMRIprep
:PROPERTIES:
:header-args:bash: :tangle no
:END:

- Reconstruct the T1 image from the multi-echo MPRAGE images.
- Only select relevant fMRI (task + rest) data and field maps.

Several subjects had multiple task based runs. In the table below I indicate the number of volumes for these runs, to help indicate which ones we should select.

| Subject | Run | Volumes |
|---------+-----+---------|
| NMD003  |   1 |      15 |
| NMD003  |   2 |      11 |
| NMD003  |   3 |     350 |
|---------+-----+---------|
| NMD005  |   1 |       7 |
| NMD005  |   2 |     350 |
|---------+-----+---------|
| NMD022  |   1 |       9 |
| NMD022  |   2 |     350 |
|---------+-----+---------|
| NMD040  |   1 |       9 |
| NMD040  |   2 |     350 |
|---------+-----+---------|
| NMD043  |   1 |      34 |
| NMD043  |   2 |      41 |
| NMD043  |   3 |      33 |
| NMD043  |   4 |     350 |

- So, it is clear that we should always select the latest run, because the ones before were terminated early.
- Note that there are also multiple field maps (runs) for some subjects. Select the last one collected.
- The copy script takes about 15 min to run.

#+NAME: prep_for_fmriprep
#+begin_src bash
#SBATCH --account=koppelmans-np
#SBATCH --mail-user=u6012627@utah.edu
#SBATCH --partition=koppelmans-shared-np
#SBATCH --job-name=prep_for_fmriprep
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --mem=12G
#SBATCH --time=2:00:00
#SBATCH -o prep_for_fmriprep-%j.out-%N
#SBATCH -e prep_for_fmriprep-%j.err-%N

# This script:
# a) reconstructs the T1 image from the multi-echo MPRAGE images
# b) copies relevant fMRI (task + rest) data and field maps from the BIDS folder

# * Environment
base="/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok\
/20251114_NMD_fMRI"
idir="${base}/20240715_BIDS"
odir="${base}/20251114_BIDS_prepped"
mkdir -p "${odir}"
fixjson="${odir}/scripts/fix_json.py"


# * Load FSL module
module load fsl


# * Function for creating the T1 image
mkt1 () {
    # ** Environment
    sub="${1}"
    iidir="${2}/${sub}/ses-01/anat"
    oodir="${3}/${sub}/ses-01/anat"
    mkdir -p "${oodir}"
    tfile=$(mktemp --suffix=".nii.gz")

    # ** Find the four MEMPRAGE images
    images=$(
        find "${iidir}" \
             -mindepth 1 \
             -maxdepth 1 \
             -type f \
             -iname "*multiecho*echo-*nii.gz" \
             | sort
    )

    # ** Merge the four MEMPRAGE images into a single 4D file
    fslmerge -t "${tfile}" $(echo ${images})

    # ** Convert the 4D image to a single T1w image
    fslmaths \
             "${tfile}" \
             -sqr -Tmean -sqrt \
             "${oodir}/${sub}_ses-01_T1w.nii.gz"
}


# * List subjects
subjects=($(
    find "${idir}" \
         -mindepth 1 \
         -maxdepth 1 \
         -type d \
         -iname "sub-*" \
         -exec basename {} \; \
         | sort
))

# ** [for testing]
# subjects=("sub-NMD001")


# * Loop over subjects to select data and create the T1w images
for sub in ${subjects[@]}; do

    # ** Reconstruct T1
    mkt1 "${sub}" "${idir}" "${odir}"

    # ** Create output folders
    mkdir -p "${odir}/${sub}/ses-01"/{func,fmap}

    # ** Some shortcuts
    andir_i="${idir}/${sub}/ses-01/anat"
    andir_o="${odir}/${sub}/ses-01/anat"
    fudir_i="${idir}/${sub}/ses-01/func"
    fudir_o="${odir}/${sub}/ses-01/func"
    fmdir_i="${idir}/${sub}/ses-01/fmap"
    fmdir_o="${odir}/${sub}/ses-01/fmap"

    # ** Copy over resting state fMRI data
    cp \
        "${fudir_i}/${sub}_ses-01_task-rest_part-mag_bold.nii.gz" \
        "${fudir_o}/${sub}_ses-01_task-rest_bold.nii.gz"
    cp \
        "${fudir_i}/${sub}_ses-01_task-rest_part-mag_bold.json" \
        "${fudir_o}/${sub}_ses-01_task-rest_bold.json"

    # ** Copy over task-based fMRI data
    # This finds all task data, sorts it in reverse order (so, last run on top),
    # and then picks the top item.
    nfile=$(
        find "${fudir_i}" -iname "*handdom*nii.gz*" \
             | sort -r \
             | head -1
         )
    cp "${nfile}" "${fudir_o}/${sub}_ses-01_task-handdom_bold.nii.gz"
    cp "${nfile/nii.gz/json}" "${fudir_o}/${sub}_ses-01_task-handdom_bold.json"

    # ** Copy over the field maps
    # Loop over reversed phase encoding directions and tasks
    for dir in AP PA; do
        for task in rest handdom; do

            # *** Define input file
            nfile=$(
                find "${fmdir_i}" -iname "*acq-${task}*${dir}_epi.nii.gz*" \
                   | sort -r \
                   | head -1
                 )

            # *** Copy over the nifti file
            cp "${nfile}" \
                "${fmdir_o}/${sub}_ses-01_acq-${task}_dir-${dir}_epi.nii.gz"

            # *** Copy over the json file
            cp "${nfile/nii.gz/json}" \
                "${fmdir_o}/${sub}_ses-01_acq-${task}_dir-${dir}_epi.json"

        done
    done

    # ** Copy over the T2w data
    # Only 39 out of 40 subjects have T2w data.
    cp \
        "${andir_i}/${sub}_ses-01_rec-bias_T2w.nii.gz" \
        "${andir_o}/${sub}_ses-01_T2w.nii.gz"
    cp \
        "${andir_i}/${sub}_ses-01_rec-bias_T2w.json" \
        "${andir_o}/${sub}_ses-01_T2w.json"

    # ** Link the reversed-phase encoding images to the fMRI data
    python3 \
        "${fixjson}" \
        --sid "${sub//sub-/}" \
        --ses "01" \
        --path "${odir}"
done


# * Copy some BIDS data meta files
for i in participants.json participants.tsv; do
    cp "${idir}/${i}" "${odir}"
done


# * Fill out the datset_description.json file
cat <<EOF>${odir}/dataset_description.json
{
  "Name": "Neuro Motor Depression study: hand clench task",
  "BIDSVersion": "1.7.0",
  "DatasetType": "raw",
  "License": "",
  "Authors": [
    "Vincent Koppelmans, (PI)"
  ],
  "Funding": [
    "Ben B & Iris Margolis Foundation"
  ],
  "EthicsApprovals": ["University of Utah, IRB_00139658"],
  "ReferencesAndLinks": [
    "https://doi.org/10.3389/fpsyt.2025.1624776",
    "https://doi.org/10.1123/jmld.2024-0105"
  ],
  "DatasetDOI": "doi:"
}
EOF


# * Add .bidsignore for the scripts folder
echo "scripts/" > "${odir}/.bidsignore"


exit
#+end_src

** TANGLE (local) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle scripts/04_prep_for_fmriprep.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<prep_for_fmriprep>>
#+end_src

** TANGLE (CHPC) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle  /ssh:u6012627@notchpeak.chpc.utah.edu:/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok/20251114_NMD_fMRI/20251114_BIDS_prepped/scripts/prep_for_fmriprep.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<prep_for_fmriprep>>
#+end_src

* Run fMRIprep
This takes about 4-5 hours per subject with the configuration below.

#+NAME: run_fMRIprep
#+begin_src bash
# * Environment
# ** IO paths
base="/uufs/chpc.utah.edu/common/home/koppelmans-group1"
idir="${base}/20230809_Kladblok/20251114_NMD_fMRI/20251114_BIDS_prepped"
odir="${base}/20230809_Kladblok/20251114_NMD_fMRI/20251115_fMRIprep"
sdir="${odir}/scripts"
mkdir -p "${sdir}"/{logs,jobs}
# ** fMRIprep version, license, and container location
fmriprep_version="25.2.3"
simg="${base}/20230809_Software/SingularityImages/fmriprep-${fmriprep_version}.simg"
fslicense="${base}/20230809_Software/license/freesurfer_license.txt"
# ** Go to log folder
cd "${sdir}/logs" || exit


# * List subjects to be processed
subjects=(
    $(find \
          "${idir}" \
          -mindepth 1 \
          -maxdepth 1 \
          -type d \
          -iname "sub-*" \
          -exec basename {} \; \
          | sort)
)


# * Create the fMRIprep script for each subject
# Loop over all subjects and create a script for fMRIprep
# for sub in sub-NMD001; do
for sub in ${subjects[@]}; do

    # ** Define job
    subject_job="${sdir}/jobs/fMRIprep_${sub}.slurm"

    # ** Create job via heredoc
    cat <<-EOF2> "${subject_job}"
	#!/bin/bash
	#SBATCH --account=koppelmans-np
	#SBATCH --mail-user=u6012627@utah.edu
	#SBATCH --partition=koppelmans-shared-np
	#SBATCH --job-name=${sub//sub-/}_fmriprep
	#SBATCH --nodes=1
	#SBATCH --ntasks=16
	#SBATCH --mem=64G
	#SBATCH --time=24:00:00
	#SBATCH -o log_${sub}_fmriprep-%j.out-%N
	#SBATCH -e log_${sub}_fmriprep-%j.err-%N


	# * Load module(s)
	module load apptainer


	# * Environment
	sub="${sub}"
	base="${base}"
	idir="\${base}/20230809_Kladblok/20251114_NMD_fMRI/20251114_BIDS_prepped"
	odir="\${base}/20230809_Kladblok/20251114_NMD_fMRI/20251115_fMRIprep"
	sdir="\${odir}/scripts/jobs"
	fmriprep_version="${fmriprep_version}"
	fmriprep="\${base}/20230809_Software/SingularityImages/fmriprep-\${fmriprep_version}.simg"
	fslicense="\${base}/20230809_Software/license/freesurfer_license.txt"


	# * Run fMRIprep
	# ** Create output folders
	mkdir -p \${odir}/derivatives/fMRIPrep_\${fmriprep_version}
	workdir=\$(mktemp -d)
	echo "Working directory: \${workdir}"

	# ** Run fMRIprep
	apptainer \\
	   run \\
	   --cleanenv \\
	   --bind \${idir}:/bids:ro \\
	   --bind \${odir}/derivatives/fMRIPrep_\${fmriprep_version}:/out \\
	   --bind \${fslicense}:/license.txt:ro \\
	   \${fmriprep} \\
	   /bids \\
	   /out \\
	   participant \\
	   --participant-label \${sub} \\
	   --cifti-output 91k \\
	   --output-spaces MNI152NLin6Asym \\
	   --output-spaces fsaverage \\
	   --output-spaces func \\
	   --notrack \\
	   --fs-license-file /license.txt \\
	   --skip_bids_validation \\
	   --nprocs 32 \\
	   --fs-subjects-dir /out/\${sub}/freesurfer \\
	   --work-dir="\${workdir}" \\
	   --clean-workdir \\
	   --stop-on-first-crash \\
	   --write-graph \\
	   --random-seed 357 \\
	   -vv

exit
EOF2

    # ** Submit job to the CHPC slurm via sbatch
    sbatch "${subject_job}"

done
#+end_src

** TANGLE (local) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle scripts/05_run_fmriprep.sh
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<run_fMRIprep>>
#+end_src

** TANGLE (CHPC) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle  /ssh:u6012627@notchpeak.chpc.utah.edu:/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok/20251114_NMD_fMRI/20251115_fMRIprep/scripts/run_fmriprep.sh
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<run_fMRIprep>>
#+end_src

* Build MRIQC on CHPC
:PROPERTIES:
:header-args:bash: :tangle no
:END:

#+NAME: build_mriqc_chpc
#+begin_src bash
#SBATCH --account=owner-guest
#SBATCH --mail-user=u6012627@utah.edu
#SBATCH --partition=notchpeak-shared-guest
#SBATCH --job-name=build_mriqc
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --mem=24G
#SBATCH --time=3:00:00
#SBATCH -o build_mriqc_sif-%j.out-%N
#SBATCH -e build_mriqc_sif-%j.err-%N

# * Environment
odir="/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Software\
/SingularityImages"

# * Load singularity/apptainer
module load apptainer

# * Version
container_version="25.0.0rc0"

# * Environment
apptainer \
    build \
    "${odir}/mriqc-${container_version}.simg" \
    "docker://nipreps/mriqc:${container_version}"

exit
#+end_src

** TANGLE (local) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle scripts/06_build_mriqc.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<build_mriqc_chpc>>
#+end_src

** TANGLE (CHPC) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle  /ssh:u6012627@notchpeak.chpc.utah.edu:/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Software/SingularityImages/build_mriqc_25.0.0rc0.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<build_mriqc_chpc>>
#+end_src

* Run MRIQC
:PROPERTIES:
:header-args:bash: :tangle no
:END:

#+NAME: run_mriqc_chpc
#+begin_src bash
#SBATCH --account=owner-guest
#SBATCH --mail-user=u6012627@utah.edu
#SBATCH --partition=koppelmans-shared-np
#SBATCH --job-name=run_mriqc
#SBATCH --nodes=1
#SBATCH --ntasks=96
#SBATCH --mem=1024G
#SBATCH --time=48:00:00
#SBATCH -o run_mriqc_sif-%j.out-%N
#SBATCH -e run_mriqc_sif-%j.err-%N

# * Environment
base="/uufs/chpc.utah.edu/common/home/koppelmans-group1"
# ** MRIQC version and container location
mriqc_version="25.0.0rc0"
mriqc="${base}/20230809_Software/SingularityImages/mriqc-${mriqc_version}.simg"
# ** IO paths
idir="${base}/20230809_Kladblok/20251114_NMD_fMRI/20251114_BIDS_prepped"
odir="${base}/20230809_Kladblok/20251114_NMD_fMRI/20251116_MRIQC/mriqc_${mriqc_version}"
mkdir -p "${odir}"


# * Load singularity/apptainer
module load apptainer


# * Run MRIQC
apptainer \
   run \
   --cleanenv \
   --bind "${idir}":/data:ro \
   --bind "${odir}":/out \
   ${mriqc} \
   /data \
   /out \
   participant \
   --nprocs 32 \
   --omp-nthreads 4 \
   --float32 \
   --write-graph \
   --no-sub \
   --notrack


exit
#+end_src

** TANGLE (local) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle scripts/07_run_mriqc.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<run_mriqc_chpc>>
#+end_src

** TANGLE (CHPC) :noexport:
:PROPERTIES:
:header-args:bash:  :shebang "#!/usr/bin/env bash"
:header-args:bash+: :tangle  /ssh:u6012627@notchpeak.chpc.utah.edu:/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok/20251114_NMD_fMRI/20251116_MRIQC/scripts/run_MRIQC.slurm
:header-args:bash+: :mkdirp yes
:header-args:bash+: :noweb yes
:END:

#+begin_src bash
<<run_mriqc_chpc>>
#+end_src

* Copy back fMRIprep and MRIQC reports
:PROPERTIES:
:header-args:bash:  :tangle scripts/08_copy_back_data.sh
:header-args:bash+: :shebang "#!/usr/bin/env bash"
:header-args:bash+: :mkdirp yes
:END:

For local inspection.
#+begin_src bash
# * Environment
rid="u6012627"
rip="notchpeak.chpc.utah.edu"
rdir="/uufs/chpc.utah.edu/common/home/koppelmans-group1/20230809_Kladblok\
/20251114_NMD_fMRI"
ldir="/datadisk/Utah/Kladblok/20201120_Margolis_NMD/20220504_Data_Processing/20251113_BayesfMRI/20251114_Preprocessing/20251117_QC"
mkdir -p "${ldir}"


# * Copy over the data
# ** fMRIprep
rsync \
    --include="*/" \
    --include="*.html" \
    --include="*.svg" \
    --exclude="*" \
    -avmhe ssh \
    "${rid}@${rip}:${rdir}/20251115_fMRIprep/derivatives/fMRIPrep_25.2.3" \
    "${ldir}"/

# ** MRIQC
#+end_src
